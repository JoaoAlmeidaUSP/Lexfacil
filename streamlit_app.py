import streamlit as st
import tempfile
import os
import PyPDF2
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import time
from datetime import datetime

# --- CONFIGURA√á√ÉO DA API (L√ìGICA ANTIGA PARA TESTE) ---
# ATEN√á√ÉO: Substitua pela sua chave real para testar.
# Lembre-se de mudar para o m√©todo st.secrets assim que validar o funcionamento.
GOOGLE_API_KEY = "AIzaSyC8POlPwAb5S95teCfWHSeAiEiejOTz7R0" 

if not GOOGLE_API_KEY or GOOGLE_API_KEY == "AIzaSyC8POlPwAb5S95teCfWHSeAiEiejOTz7R0":
    st.error("‚ö†Ô∏è ATEN√á√ÉO: A CHAVE API DO GEMINI N√ÉO FOI DEFINIDA CORRETAMENTE!")
    st.error("Por favor, substitua 'SUA_CHAVE_API_AQUI' pela sua chave API real na vari√°vel GOOGLE_API_KEY no c√≥digo-fonte para poder testar.")
    st.warning("Lembre-se: Ap√≥s o teste, √© altamente recomend√°vel usar o m√©todo de 'secrets' do Streamlit para proteger sua chave.")
    st.stop()

try:
    genai.configure(api_key=GOOGLE_API_KEY)
except Exception as e:
    st.error(f"‚ùå Falha ao configurar a API do Gemini com a chave fornecida: {str(e)}")
    st.stop()


# --- CONFIGURA√á√ÉO DO MODELO GEMINI ---
try:
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }
    model = genai.GenerativeModel(
        model_name='gemini-1.5-flash-latest',
        safety_settings=safety_settings
    )
except Exception as e:
    st.error(f"‚ùå Falha ao configurar o modelo Gemini: {str(e)}")
    st.stop()

# --- INICIALIZA√á√ÉO DO SESSION STATE ---
if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []
if 'texto_lei' not in st.session_state:
    st.session_state.texto_lei = ""
if 'nome_documento' not in st.session_state:
    st.session_state.nome_documento = ""
if 'persona_usuario' not in st.session_state:
    st.session_state.persona_usuario = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Cidad√£o"

# --- FUN√á√ïES AUXILIARES E DE PROCESSAMENTO ---

def extrair_texto_pdf(uploaded_file):
    """Extrai texto de um arquivo PDF carregado."""
    texto = ""
    try:
        # Usando o arquivo em mem√≥ria diretamente, sem salvar em disco
        leitor = PyPDF2.PdfReader(uploaded_file)
        for pagina in leitor.pages:
            texto_pagina = pagina.extract_text()
            if texto_pagina:
                texto += texto_pagina
        return texto.strip()
    except Exception as e:
        st.error(f"Erro ao processar o PDF: {str(e)}")
        return ""

# --- OTIMIZA√á√ÉO: CACHING E RATE LIMITING NA CHAMADA DA API ---
@st.cache_data(show_spinner=False) # Cache para evitar chamadas repetidas
def call_gemini_api_with_retry(_prompt_text, task_name="tarefa", max_retries=3):
    """
    Chama a API Gemini com tratamento de erro e retentativas (exponential backoff).
    O decorator @st.cache_data garante que, para o mesmo _prompt_text,
    a fun√ß√£o n√£o ser√° executada novamente, retornando o resultado salvo em cache.
    """
    for attempt in range(max_retries):
        try:
            response = model.generate_content(_prompt_text)
            if response.candidates:
                return response.text
            elif response.prompt_feedback and response.prompt_feedback.block_reason:
                return f"Conte√∫do bloqueado: {response.prompt_feedback.block_reason.name}"
            else:
                return "Nenhum conte√∫do gerado."
        except Exception as e:
            if "429" in str(e): # Erro de Quota
                wait_time = 2 ** attempt # Exponential backoff: 1, 2, 4 segundos
                st.warning(f"‚ö†Ô∏è Cota da API excedida. Tentando novamente em {wait_time} segundos...")
                time.sleep(wait_time)
            else:
                st.error(f"‚ùå Erro durante a {task_name} com a API Gemini: {str(e)}")
                return f"Erro na API: {str(e)}"
    return "Erro: A API continua indispon√≠vel ap√≥s v√°rias tentativas."


def criar_contexto_inicial():
    """Cria o contexto inicial para o agente conversacional."""
    if not st.session_state.texto_lei:
        return ""

    personas = {
        "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Cidad√£o": "Use linguagem ultra-simples, foque no impacto pessoal e familiar, d√™ exemplos do cotidiano.",
        "üë®‚Äçüíº Empres√°rio": "Foque em impactos comerciais, custos, prazos de adequa√ß√£o, riscos para neg√≥cios.",
        "üë©‚Äç‚öñÔ∏è Advogado": "Pode usar termos t√©cnicos, foque em interpreta√ß√£o jur√≠dica, precedentes, aplica√ß√£o pr√°tica.",
        "üèõÔ∏è Servidor P√∫blico": "Foque na aplica√ß√£o da norma, procedimentos, compet√™ncias dos √≥rg√£os."
    }
    contexto_persona = personas.get(st.session_state.persona_usuario, personas["üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Cidad√£o"])
    texto_contexto = st.session_state.texto_lei[:50000] # Amostra para o contexto

    return f"""
    DOCUMENTO JUR√çDICO CARREGADO: {st.session_state.nome_documento}
    PERFIL DO USU√ÅRIO: {st.session_state.persona_usuario}
    INSTRU√á√ïES ESPEC√çFICAS: {contexto_persona}

    TEXTO DA LEI/NORMA (IN√çCIO):
    {texto_contexto}
    ---
    INSTRU√á√ïES PARA O AGENTE:
    Voc√™ √© o LexF√°cil, um assistente jur√≠dico. Sua miss√£o √© simplificar textos normativos.
    Adapte sua linguagem ao perfil do usu√°rio. Seja objetivo, amig√°vel e baseie-se sempre no documento carregado.
    """

# --- FUN√á√ïES PRINCIPAIS COM CACHE ---
@st.cache_data(show_spinner="Analisando legibilidade...")
def analisar_legibilidade_gemini(_texto):
    prompt = f"""
    Analise a legibilidade deste texto jur√≠dico. Forne√ßa uma avalia√ß√£o sobre:
    1. Complexidade Lingu√≠stica (1-F√°cil a 10-Dif√≠cil)
    2. Uso de Jarg√£o Jur√≠dico (Baixo, M√©dio, Alto)
    3. Estrutura das Frases (Curtas/Longas, Claras/Complexas)
    4. P√∫blico-Alvo Ideal
    5. Recomenda√ß√µes para Simplifica√ß√£o (3 a 5 a√ß√µes)
    Formate a resposta em MARKDOWN.

    Texto para An√°lise:
    ---
    {_texto}
    """
    return call_gemini_api_with_retry(prompt, "An√°lise de Legibilidade")

@st.cache_data(show_spinner="Gerando resumo...")
def gerar_resumo_gemini(_texto):
    prompt = f"""
    Gere um resumo conciso e em linguagem acess√≠vel do texto jur√≠dico fornecido.
    - Identifique os pontos principais.
    - Explique o significado pr√°tico dos artigos mais relevantes.
    - Evite jarg√µes. Se um termo t√©cnico for essencial, explique-o.
    - Use MARKDOWN para melhor legibilidade.

    Texto Jur√≠dico para Resumir:
    ---
    {_texto}
    """
    return call_gemini_api_with_retry(prompt, "Resumo Simplificado")

@st.cache_data(show_spinner="Criando casos pr√°ticos...")
def gerar_casos_praticos(_texto):
    texto_amostra = _texto[:30000]
    prompt = f"""
    Com base no texto jur√≠dico, crie 3 casos pr√°ticos de como esta lei se aplica no dia a dia.
    Para cada caso, forne√ßa: Situa√ß√£o, Aplica√ß√£o da Lei, Consequ√™ncias e Dica Pr√°tica.
    Use MARKDOWN.

    Texto da Lei:
    ---
    {texto_amostra}
    """
    return call_gemini_api_with_retry(prompt, "Gera√ß√£o de Casos Pr√°ticos")

@st.cache_data(show_spinner="Extraindo prazos...")
def extrair_prazos_importantes(_texto):
    prompt = f"""
    Analise este texto jur√≠dico e identifique TODOS os prazos, datas e per√≠odos importantes.
    Para cada um, forne√ßa: Prazo, Finalidade, Respons√°vel, Consequ√™ncia do n√£o cumprimento e Artigo/Se√ß√£o.
    Se n√£o encontrar prazos, informe isso claramente. Use MARKDOWN.

    Texto da Lei:
    ---
    {_texto}
    """
    return call_gemini_api_with_retry(prompt, "Extra√ß√£o de Prazos")

@st.cache_data(show_spinner="Buscando no documento...")
def busca_semantica(_texto, _consulta):
    texto_amostra = _texto[:50000]
    prompt = f"""
    O usu√°rio quer encontrar informa√ß√µes sobre: "{_consulta}"
    Procure no texto jur√≠dico abaixo todas as informa√ß√µes relacionadas.
    Retorne: Trechos Relevantes (com cita√ß√£o do artigo/se√ß√£o), Explica√ß√£o Simplificada e Palavras-chave Encontradas.
    Se n√£o encontrar, informe claramente.

    Texto da Lei:
    ---
    {texto_amostra}
    """
    return call_gemini_api_with_retry(prompt, "Busca Sem√¢ntica")

def processar_pergunta_chat(pergunta):
    """Processa uma pergunta no chat (n√£o usa cache, pois a conversa √© din√¢mica)."""
    contexto_base = criar_contexto_inicial()
    historico_recente = ""
    ultimas_msgs = st.session_state.chat_messages[-6:]
    for msg in ultimas_msgs:
        papel = "USU√ÅRIO" if msg["role"] == "user" else "ASSISTENTE"
        historico_recente += f"{papel}: {msg['content']}\n"

    prompt = f"""
    {contexto_base}

    HIST√ìRICO DA CONVERSA:
    {historico_recente}

    PERGUNTA ATUAL DO USU√ÅRIO:
    {pergunta}

    Responda de forma clara, pr√°tica e acess√≠vel, sempre baseado no documento jur√≠dico carregado.
    """
    return call_gemini_api_with_retry(prompt, "resposta do chat")


# --- INTERFACE STREAMLIT ---
st.set_page_config(page_title="LexF√°cil", layout="wide", initial_sidebar_state="expanded")

# --- SIDEBAR ---
with st.sidebar:
    st.title("üìò LexF√°cil")
    st.markdown("**Seu assistente jur√≠dico inteligente**")

    st.markdown("### üë§ Seu Perfil")
    persona_escolhida = st.selectbox(
        "Como voc√™ quer que eu te ajude?",
        options=["üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Cidad√£o", "üë®‚Äçüíº Empres√°rio", "üë©‚Äç‚öñÔ∏è Advogado", "üèõÔ∏è Servidor P√∫blico"],
        index=0,
        help="Escolha seu perfil para respostas personalizadas"
    )
    if persona_escolhida != st.session_state.persona_usuario:
        st.session_state.persona_usuario = persona_escolhida

    st.markdown("### üìÑ Carregar Documento")
    uploaded_file = st.file_uploader("Envie o PDF da lei ou norma", type=["pdf"])

    if uploaded_file:
        if uploaded_file.name != st.session_state.get('nome_documento'):
            with st.spinner("Processando documento..."):
                texto_extraido = extrair_texto_pdf(uploaded_file)
                if texto_extraido:
                    st.session_state.clear()
                    st.session_state.texto_lei = texto_extraido
                    st.session_state.nome_documento = uploaded_file.name
                    st.session_state.persona_usuario = persona_escolhida
                    st.session_state.chat_messages = []

                    boas_vindas = f"Ol√°! Recebi o documento **{uploaded_file.name}**. Como posso te ajudar a entend√™-lo?"
                    st.session_state.chat_messages.append({"role": "assistant", "content": boas_vindas})
                    st.success("‚úÖ Documento carregado!")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("‚ùå N√£o foi poss√≠vel extrair texto do PDF.")

    if st.session_state.texto_lei:
        st.markdown("### üõ†Ô∏è Ferramentas Inteligentes")
        
        def adicionar_ao_chat(titulo, conteudo_gerado, pergunta_usuario):
            st.session_state.chat_messages.append({"role": "user", "content": pergunta_usuario})
            st.session_state.chat_messages.append({"role": "assistant", "content": f"## {titulo}\n\n{conteudo_gerado}"})

        if st.button("üìä An√°lise de Legibilidade", use_container_width=True):
            resultado = analisar_legibilidade_gemini(st.session_state.texto_lei)
            adicionar_ao_chat("üìä An√°lise de Legibilidade", resultado, "Fa√ßa uma an√°lise de legibilidade do documento.")

        if st.button("üìÑ Resumo Simplificado", use_container_width=True):
            resultado = gerar_resumo_gemini(st.session_state.texto_lei)
            adicionar_ao_chat("üìÑ Resumo Simplificado", resultado, "Gere um resumo simplificado do documento.")

        if st.button("üéØ Casos Pr√°ticos", use_container_width=True):
            resultado = gerar_casos_praticos(st.session_state.texto_lei)
            adicionar_ao_chat("üéØ Casos Pr√°ticos", resultado, "Gere casos pr√°ticos de aplica√ß√£o da lei.")

        if st.button("‚è∞ Prazos Importantes", use_container_width=True):
            resultado = extrair_prazos_importantes(st.session_state.texto_lei)
            adicionar_ao_chat("‚è∞ Prazos Importantes", resultado, "Quais s√£o os prazos importantes desta lei?")
        
        st.markdown("### üîç Busca Inteligente")
        busca_query = st.text_input("Buscar por conceito ou tema:", placeholder="Ex: multas, prazos...")
        if st.button("Buscar", use_container_width=True) and busca_query:
            resultado = busca_semantica(st.session_state.texto_lei, busca_query)
            adicionar_ao_chat(f"üîç Resultados da Busca: '{busca_query}'", resultado, f"Buscar por: {busca_query}")

        st.markdown("### üìã Documento Atual")
        st.info(f"**{st.session_state.nome_documento}**\n\n{len(st.session_state.texto_lei):,} caracteres")


# --- √ÅREA PRINCIPAL - CHAT ---
st.title("üí¨ Converse sobre sua Lei")

if not st.session_state.texto_lei:
    st.info("Para come√ßar, carregue um documento PDF na barra lateral.")
else:
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Digite sua pergunta sobre a lei..."):
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                resposta = processar_pergunta_chat(prompt)
                st.markdown(resposta)
                st.session_state.chat_messages.append({"role": "assistant", "content": resposta})

# Footer
st.markdown("---")
st.markdown("ü§ñ **LexF√°cil** - Transformando juridiqu√™s em linguagem acess√≠vel com IA")
